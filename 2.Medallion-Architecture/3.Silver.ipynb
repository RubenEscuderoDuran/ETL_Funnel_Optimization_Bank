{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "196db72a-92c3-400b-8fb3-640e2deb4a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### We need to create gold tables to start with the data transformations. First, we need a table to join the funnel data with catalog data, in this table we need to add a new column 'quality_check' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d7094d-4953-49dd-b85f-e145323d499f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, col, when, max, count, current_timestamp, lit, min, StructType, datediff\n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, DateType, TimestampType\n",
    "from delta.tables import DeltaTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad378d98-6af7-447c-9454-37dce2ea48d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#This table are created to join with catalog data.\n",
    "\n",
    "schema_funnel = StructType([\n",
    "    StructField(\"client_id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"app\", StringType(), True),\n",
    "    StructField(\"stage\", StringType(), True),\n",
    "    StructField(\"register_date\", DateType(), True),\n",
    "    StructField(\"complete_process\", IntegerType(), True),\n",
    "    StructField('quality_check', StringType(), True),\n",
    "    StructField(\"ingestion_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "funnel_gold_df = spark.createDataFrame([], schema_funnel)\n",
    "\n",
    "funnel_gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"path\", \"abfss://gold@projectamebank.dfs.core.windows.net/clients_funnel\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf8be550-6acf-4f06-9daa-d097762a0877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## For the clients we need to create a table and use the pivot functions to pivot in the colum stage, separate by stage using the data in silver table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "938e6211-42d3-438c-ab52-4a3103fd5830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Table for the pivoted stages and register_date\n",
    "\n",
    "schema_clients = StructType([\n",
    "    StructField('client_id', StringType(), True),\n",
    "    StructField('complete_process', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('state', StringType(), True),\n",
    "    StructField('email', StringType(), True),\n",
    "    StructField('app', StringType(), True),\n",
    "    StructField('introduction', DateType(), True),\n",
    "    StructField('data_request', DateType(), True),\n",
    "    StructField('data_validation', DateType(), True),\n",
    "    StructField('facial_recognition', DateType(), True),\n",
    "    StructField('signature', DateType(), True),\n",
    "    StructField('data_confirmation', DateType(), True),\n",
    "    StructField('ingestion_time', TimestampType(), True),\n",
    "    StructField('update_date', TimestampType(), True)\n",
    "])\n",
    "\n",
    "clients_gold_df = spark.createDataFrame([], schema_clients)\n",
    "\n",
    "clients_gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"path\", \"abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage\") \\\n",
    "    .save()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf1f13c5-4260-43c9-8661-4d839cbc6099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ok, our data are inserted into silver tables, cleaned and transformed. Now we can work and apply data transformations for audit.\n",
    "- We can apply the inner join  funnel data with catalog data. This will help us keep track of users and their information in each process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e883db-3023-4f1b-a098-bfe7bea36af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Load the funnel data\n",
    "funnel_data = spark.read \\\n",
    "                   .format('delta') \\\n",
    "                    .load('abfss://silver@projectamebank.dfs.core.windows.net/users_funnel') \\\n",
    "                    .select('client_id', 'app', 'stage', 'register_date', 'complete_process') \\\n",
    "                    .withColumn('quality_check', when((length(col('client_id')) == 5) & (col('complete_process').isin(0, 1)), 'Passed') \\\n",
    "                    .otherwise('Not Passed'))\n",
    "#Add a new column quality_check, to check if the client_id is valid or not and if the complete_process is 0 or 1.\n",
    "\n",
    "#Applying the same for catalog \n",
    "catalog_data = spark.read \\\n",
    "                    .format('delta') \\\n",
    "                    .load('abfss://silver@projectamebank.dfs.core.windows.net/catalog') \\\n",
    "                    .select('client_id', 'name', 'age', 'state', 'email')\n",
    "\n",
    "#Now, apply the join, to get the final df, this final df is merge with the gold table and validate some information \n",
    "join_df = funnel_data.join(catalog_data, on='client_id', how=\"inner\") \\\n",
    "                     .select('client_id', 'name', 'age', 'state', 'email', 'app', 'stage', 'register_date', 'complete_process', 'quality_check')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd530d25-2655-4e7a-baf9-ee263441a311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we need to do the merge into gold table\n",
    "gold_path = 'abfss://gold@projectamebank.dfs.core.windows.net/clients_funnel'\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "\n",
    "delta_table.alias('t').merge(\n",
    "    join_df.alias('s'),\n",
    "    ' t.client_id = s.client_id and t.stage = s.stage'\n",
    "    ).whenNotMatchedInsert(\n",
    "        values = {\n",
    "            'client_id': 's.client_id',\n",
    "            'name': 's.name',\n",
    "            'age': 's.age',\n",
    "            'state': 's.state',\n",
    "            'email': 's.email',\n",
    "            'app': 's.app',\n",
    "            'stage': 's.stage',\n",
    "            'register_date': 's.register_date',\n",
    "            'complete_process': 's.complete_process',\n",
    "            'quality_check': 's.quality_check',\n",
    "            'ingestion_date': current_timestamp() #Add the ingestion date when the data is inserted into the table\n",
    "        }\n",
    "    ).execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983425d1-cfec-45f4-a64a-15d9a96e0033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Now we have our table cliets_funnel join, we can do a pivot. Because, we need to separate the stages one by one to know the date stage by stage, to do that, we use the table in gold container. But, we can see the stages are in spanish, we need the change the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce9e475c-4406-4e21-a242-c8eea1e10fb3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761702416116}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clients_df = spark.read \\\n",
    "                  .format('delta') \\\n",
    "                  .option('header', True) \\\n",
    "                  .load('abfss://gold@projectamebank.dfs.core.windows.net/clients_funnel') \\\n",
    "                  .select('client_id', 'complete_process', 'name', 'age', 'state', 'email', 'app', 'stage', 'register_date') \\\n",
    "                  .withColumn('stage',\n",
    "                                     when(col('stage') == 'Introduccion', 'introduction')\n",
    "                                    .when(col('stage') == 'Solicitud de datos', 'data_request')\n",
    "                                    .when(col('stage') == 'Validacion de datos', 'data_validation')\n",
    "                                    .when(col('stage') == 'Reconocimiento facial', 'facial_recognition')\n",
    "                                    .when(col('stage') == 'Firma', 'signature')\n",
    "                                    .when(col('stage') == 'Confirmacion de datos', 'data_confirmation')) \n",
    "\n",
    "#Use a pivot function to create a new table with the stages and the date per stage.\n",
    "pivot_df = clients_df \\\n",
    "                     .groupBy('client_id', 'complete_process', 'name', 'age', 'state', 'email', 'app') \\\n",
    "                     .pivot('stage', [\n",
    "                         'introduction',\n",
    "                         'data_request',\n",
    "                         'data_validation',\n",
    "                         'facial_recognition',\n",
    "                         'signature',\n",
    "                         'data_confirmation'\n",
    "                     ]) \\\n",
    "                     .agg(min(col('register_date'))) \\\n",
    "                     .orderBy('client_id')\n",
    "\n",
    "display(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291fa40a-a3ce-453b-8948-68720bb0c716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we need to do the merge pivot_df into gold table pv_clients_stage\n",
    "gold_pv_path = 'abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage'\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, gold_pv_path)\n",
    "\n",
    "(\n",
    "    delta_table.alias('t')\n",
    "    .merge(\n",
    "        pivot_df.alias('s'),\n",
    "        't.client_id = s.client_id'\n",
    "    )\n",
    "    .whenMatchedUpdate(\n",
    "        condition=(\n",
    "            (col('t.name') != col('s.name')) |\n",
    "            (col('t.email') != col('s.email')) |\n",
    "            (col('t.age') != col('s.age')) |\n",
    "            (col('t.state') != col('s.state')) |\n",
    "            (col('t.complete_process') != col('s.complete_process')) |\n",
    "            (col('t.introduction') != col('s.introduction')) |\n",
    "            (col('t.data_request') != col('s.data_request')) |\n",
    "            (col('t.data_validation') != col('s.data_validation')) |\n",
    "            (col('t.facial_recognition') != col('s.facial_recognition')) |\n",
    "            (col('t.signature') != col('s.signature')) |\n",
    "            (col('t.data_confirmation') != col('s.data_confirmation'))\n",
    "        ),\n",
    "        set={\n",
    "            'name': col('s.name'),\n",
    "            'email': col('s.email'),\n",
    "            'age': col('s.age'),\n",
    "            'state': col('s.state'),\n",
    "            'complete_process': col('s.complete_process'),\n",
    "            'introduction': col('s.introduction'),\n",
    "            'data_request': col('s.data_request'),\n",
    "            'data_validation': col('s.data_validation'),\n",
    "            'facial_recognition': col('s.facial_recognition'),\n",
    "            'signature': col('s.signature'),\n",
    "            'data_confirmation': col('s.data_confirmation'),\n",
    "            'update_date': current_timestamp() #When the data has modified, add the current timestamp\n",
    "        }\n",
    "    )\n",
    "    .whenNotMatchedInsert(\n",
    "        values={\n",
    "            'client_id': col('s.client_id'),\n",
    "            'complete_process': col('s.complete_process'),\n",
    "            'name': col('s.name'),\n",
    "            'age': col('s.age'),\n",
    "            'state': col('s.state'),\n",
    "            'email': col('s.email'),\n",
    "            'app': col('s.app'),\n",
    "            'introduction': col('s.introduction'),\n",
    "            'data_request': col('s.data_request'),\n",
    "            'data_validation': col('s.data_validation'),\n",
    "            'facial_recognition': col('s.facial_recognition'),\n",
    "            'signature': col('s.signature'),\n",
    "            'data_confirmation': col('s.data_confirmation'),\n",
    "            'ingestion_time': current_timestamp() #When the data not changed, we add the ingest into gold table.\n",
    "        }\n",
    "    )\n",
    "    .execute()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4da716-1205-4076-bb07-98cb25a16d60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Now,we can do some calculations, for example:\n",
    "- Clients that finished all stages\n",
    "- Total time between the firts and last stage for each client\n",
    "- Most frequent abandonment stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fff7d38-fe45-4ec4-ba36-fc3999836fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Clients that finished all stages\n",
    "clients_finished_all = spark.read.format('delta').load('abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage') \\\n",
    "                                 .filter(col('complete_process') == 1) \\\n",
    "                                 .select(count('*').alias('finished_all'))\n",
    "display(clients_finished_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7593171c-c54a-4ae6-87bb-2f3c7d45d5c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Clients didn't finish the process\n",
    "clients_not_finished_all = spark.read.format('delta').load('abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage') \\\n",
    "                                 .filter(col('complete_process') == 0) \\\n",
    "                                 .select(count('*')).alias('didnt_finish_all')\n",
    "display(clients_not_finished_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ef27954-dab6-4c83-b677-711554af23ec",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761590427757}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Total time between the firts and last stage for each client\n",
    "total_time = spark.read.format('delta').load('abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage') \\\n",
    "                        .filter(col('complete_process') == 1) \\\n",
    "                        .groupBy('client_id', 'complete_process') \\\n",
    "                        .agg(max('data_confirmation').alias('max'), min('introduction').alias('min')) \\\n",
    "                        .withColumn('total_time_days', datediff(col('max'), col('min'))) \\\n",
    "                        .orderBy('client_id')\n",
    "display(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5916a957-2f7a-4d9c-b49e-e6820f2f08f2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Stages\":137},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761616745019}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Most abandoned stage abandoned \n",
    "most_abandoned_stage = spark.read.format('delta').load('abfss://gold@projectamebank.dfs.core.windows.net/pv_clients_stage') \\\n",
    "                                 .filter(col('complete_process') == 0) \\\n",
    "                                 .agg(\n",
    "                                       count(\n",
    "                                              when(\n",
    "                                                col('data_request').isNull() &\n",
    "                                                col('data_validation').isNull() &\n",
    "                                                col('facial_recognition').isNull() &\n",
    "                                                col('signature').isNull() &\n",
    "                                                col('data_confirmation').isNull(), 1)).alias('TI'),\n",
    "                                       count(\n",
    "                                             when(\n",
    "                                                   col('data_request').isNotNull() &\n",
    "                                                col('data_validation').isNull() &\n",
    "                                                col('facial_recognition').isNull() &\n",
    "                                                col('signature').isNull() &\n",
    "                                                col('data_confirmation').isNull(), 1)).alias('TSD'),\n",
    "                                       count(\n",
    "                                             when(\n",
    "                                                col('data_validation').isNotNull() &\n",
    "                                                col('facial_recognition').isNull() &\n",
    "                                                col('signature').isNull() &\n",
    "                                                col('data_confirmation').isNull(), 1)).alias('TVD'),\n",
    "                                       count(\n",
    "                                             when(\n",
    "                                                col('facial_recognition').isNotNull() &\n",
    "                                                col('signature').isNull() &\n",
    "                                                col('data_confirmation').isNull(), 1)).alias('TRF'),\n",
    "                                       count(\n",
    "                                             when(\n",
    "                                                col('signature').isNotNull() &\n",
    "                                                col('data_confirmation').isNull(), 1)).alias('TF'),\n",
    "                                       count(\n",
    "                                             when(\n",
    "                                                col('data_confirmation').isNotNull(), 1)).alias('TCD')\n",
    "                                          ) \\\n",
    "                                     .orderBy('TI')   \n",
    "display(most_abandoned_stage)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
